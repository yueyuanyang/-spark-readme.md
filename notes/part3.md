### Spark RDD的理解

#### 定义

RDD(Resilient Distributed Datasets,弹性分布式数据集)是一个分区的只读记录的集合。

RDD只能通过在稳定的存储器或其他RDD的数据上的确定性操作来创建。

我们把这些操作称作变换以区别其他类型的操作。例如 map,filter和join。

RDD在任何时候都不需要被”物化”(进行实际的变换并最终写入稳定的存储器上)。实际上，一个RDD有足够的信息描述着其如何从其他稳定的存储器上的数据生成。它有一个强大的特性：从本质上说，若RDD失效且不能重建，程序将不能引用该RDD。

而用户可以控制RDD的其他两个方面：持久化和分区。用户可以选择重用哪个RDD，并为其制定存储策略(比如，内存存储)。也可以让RDD中的数据根据记录的key分布到集群的多个机器。 这对位置优化来说是有用的，比如可用来保证两个要jion的数据集都使用了相同的哈希分区方式
